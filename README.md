# ğŸ§  easyResearch - AI Research Assistant

<p align="center">
  <b>Advanced Research Assistant powered by RAG (Retrieval-Augmented Generation)</b>
</p>

---

## ğŸ“– Introduction

**easyResearch** is an AI application that helps you query and ask questions on your own documents. The system uses advanced RAG technology to:

- ğŸ“„ Read and analyze documents (PDF, DOCX, TXT, Code)
- ğŸ” Hybrid Search (Vector + BM25 keyword search)
- ğŸ’¬ Answer questions based on document content
- ğŸŒ Multi-language support (Vietnamese & English)
- ğŸ¯ Cross-Encoder Reranking for better accuracy

## âœ¨ Features

| Feature                    | Description                                        |
| -------------------------- | -------------------------------------------------- |
| ğŸ“‚ **Notebook Management** | Organize documents by project/topic separately     |
| ğŸ“¥ **Multi-format Import** | Support PDF, DOCX, TXT, Python code                |
| ğŸ§  **Parent Document**     | Small chunks for search, large chunks for context  |
| âš¡ **GPU Acceleration**    | Optimized for NVIDIA GPU (CUDA)                    |
| ğŸ”‘ **Multi-LLM Support**   | Groq (LLaMA 3.3) or Google Gemini                  |
| ğŸŒ **RESTful API**         | Easy integration via FastAPI                       |
| ğŸ¨ **Modern UI**           | Gradient UI, collapsible panels, progress tracking |
| ğŸ“Š **Dashboard**           | Project stats (chunks, files, size)                |
| ğŸ“ **Auto-Summarizer**     | Automatic summary generation after document upload |
| ğŸ”„ **Smart Context**       | Only contextualize when needed (faster response)   |

## ğŸ—ï¸ System Architecture

```
easyResearch/
â”œâ”€â”€ app.py              # Streamlit Interface (Web UI)
â”œâ”€â”€ main.py             # FastAPI Server (REST API)
â”œâ”€â”€ core/
â”‚   â”œâ”€â”€ loader.py       # Parent Document Retrieval & Smart Splitter
â”‚   â”œâ”€â”€ embedder.py     # Vectorization & ChromaDB Management
â”‚   â”œâ”€â”€ generator.py    # Advanced RAG Pipeline
â”‚   â””â”€â”€ summarizer.py   # Auto-Summarization
â”œâ”€â”€ database/
â”‚   â””â”€â”€ chroma_db/      # Vector Database Storage
â””â”€â”€ uploads/            # Temporary File Storage
```

### Tech Stack

- **LLM**: Groq (LLaMA 3.3 70B) or Google Gemini 2.0 Flash
- **Embedding**: HuggingFace `paraphrase-multilingual-MiniLM-L12-v2`
- **Reranker**: CrossEncoder `ms-marco-MiniLM-L-6-v2`
- **Vector DB**: ChromaDB
- **Keyword Search**: BM25 (rank-bm25)
- **Framework**: LangChain, Streamlit, FastAPI

## ğŸ”¬ Advanced RAG Pipeline

```
Question â†’ Smart Contextualization â†’ Vector Search
                                          â†“
                                    BM25 Scoring
                                          â†“
                              Cross-Encoder Reranking
                                          â†“
               Hybrid Score (0.7Ã—Rerank + 0.3Ã—BM25)
                                          â†“
                 Parent Document Retrieval â†’ LLM Answer
```

### Key Optimizations

| Component                   | Benefit                                                 |
| --------------------------- | ------------------------------------------------------- |
| **Hybrid Search**           | Combines semantic + keyword matching                    |
| **Parent Document**         | Small chunks (400) for search, large (2000) for context |
| **Smart Contextualization** | Only calls LLM when pronouns/references detected        |
| **Cross-Encoder**           | Local reranking (no API calls)                          |

## ğŸš€ Installation

### System Requirements

- Python 3.10+
- NVIDIA GPU with CUDA (recommended) or CPU

### Installation Steps

1. **Clone repository**

   ```bash
   git clone https://github.com/your-username/easyResearch.git
   cd easyResearch
   ```

2. **Create virtual environment**

   ```bash
   python -m venv venv

   # Windows
   venv\Scripts\activate

   # Linux/Mac
   source venv/bin/activate
   ```

3. **Install dependencies**

   ```bash
   pip install -r requirements.txt
   ```

4. **Configure API Key**

   Create a `.env` file in the root directory:

   ```env
   GROQ_API_KEY=your_groq_api_key_here
   GOOGLE_API_KEY=your_gemini_api_key_here  # Optional
   ```

   > ğŸ’¡ Get Groq API Key at [console.groq.com](https://console.groq.com)
   > ğŸ’¡ Get Gemini API Key at [aistudio.google.com/apikey](https://aistudio.google.com/apikey)

## ğŸ“– Usage Guide

### Run Web UI (Streamlit)

```bash
streamlit run app.py
```

Access: `http://localhost:8501`

### Run REST API (FastAPI)

```bash
uvicorn main:app --reload
```

Access Swagger UI: `http://localhost:8000/docs`

## ğŸ”Œ API Endpoints

### 1. Question & Answer - `POST /ask`

```json
{
  "question": "Your question here",
  "collection_name": "notebook_name"
}
```

**Response:**

```json
{
  "answer": "AI generated answer",
  "sources": ["file1.pdf", "file2.docx"]
}
```

### 2. Upload Document - `POST /upload`

```bash
curl -X POST "http://localhost:8000/upload?collection_name=my_research" \
  -F "file=@document.pdf"
```

## âš™ï¸ Advanced Configuration

### Parent Document Chunking

| File Type       | Parent Size | Child Size | Notes                      |
| --------------- | ----------- | ---------- | -------------------------- |
| PDF, DOCX       | 2500        | 500        | Preserve long text context |
| Code (.py, .js) | 1500        | 400        | Split by function/class    |
| JSON, CSV       | 1000        | 300        | Don't split mid-object     |
| Default Text    | 800         | 100        | Balanced                   |

### Search Parameters

- **Hybrid Score**: `0.7 Ã— Rerank + 0.3 Ã— BM25`
- **k**: Number of documents to return (default: 10)
- **Min Score Threshold**: 0.1 (filter low relevance)

## ğŸ“ Project Management

- **Create New**: Select "â• Create new..." from dropdown and name it
- **Switch**: Select project from dropdown - badge shows active project
- **Delete Project**: Click "ğŸ—‘ï¸ Delete this project" button
- **Clear Chat**: Click "ğŸ§¹ Clear chat history" to reset conversation
- **Auto-Summary**: Generated automatically after uploading documents

### Sidebar Interface

| Panel                   | Function                                  |
| ----------------------- | ----------------------------------------- |
| ğŸ“‚ **Project**          | Select/create/delete with stats dashboard |
| ğŸ“„ **Summary**          | Auto-generated project overview           |
| ğŸ“Š **Statistics**       | Chunks, files, storage size               |
| ğŸ“¥ **Import Documents** | Upload files with progress bar            |
| âš™ï¸ **Settings**         | LLM provider, API Key, search depth       |

## ğŸ› ï¸ Troubleshooting

| Issue           | Solution                                   |
| --------------- | ------------------------------------------ |
| Missing API Key | Create `.env` file or enter key in sidebar |
| CUDA Error      | Check NVIDIA driver or run on CPU          |
| VRAM Overflow   | Reduce batch size in `embedder.py`         |
| Slow Response   | Already optimized (1-2 LLM calls only)     |

## ğŸ“„ License

MIT License - See [LICENSE](LICENSE) file for more details.

---

<p align="center">
  Made with â¤ï¸ by easyResearch
